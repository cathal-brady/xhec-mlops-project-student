{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abalone Age Prediction Using Machine Learning\n",
    "\n",
    "In this notebook, we aim to implement a simple yet effective machine learning model to predict the age of abalones based on their physical attributes. The dataset contains measurements such as length, diameter, height, and weight, which are used to estimate the age of abalones.\n",
    "\n",
    "## Approach and Guidelines\n",
    "\n",
    "- **Model Simplicity**: For this first version, we will use a **Linear Regression** model. This is a straightforward model that helps capture linear relationships between the input features and the target variable (age).\n",
    "- **Experiment Tracking with MLflow**: Throughout our experimentation, we use **MLflow** to track different model runs, hyperparameters, and performance metrics such as MSE and R². This allows us to compare different models and easily monitor the progress of our experiments.\n",
    "- **Repository Guidelines**: While we track our experiments using MLflow, **no MLflow data will be pushed** to the repository. Only the code used for running the experiments will be versioned for future reference.\n",
    "\n",
    "## Model Selection and Results\n",
    "\n",
    "After trying several models, including **Ridge Regression** and **Extended Ridge**, we concluded that **Linear Regression** was the most effective in predicting the age of abalones. The simplicity of the model, combined with its reasonable performance, made it the best choice for this task.\n",
    "\n",
    "However, it is worth mentioning that we also explored **Extended Ridge Regression** with optimized parameters. Below are the details of the best configuration:\n",
    "\n",
    "- **Best Parameters for Extended Ridge**:\n",
    "  - `alpha`: 1.0\n",
    "  - `fit_intercept`: True\n",
    "  - `solver`: lsqr\n",
    "- **Best MSE for Extended Ridge**: 4.889\n",
    "- **Test MSE for Extended Ridge**: 4.891\n",
    "- **Test R² for Extended Ridge**: 0.548\n",
    "\n",
    "In conclusion, after comparing the different models, **Linear Regression** emerged as the best model due to its simplicity, interpretability, and competitive performance in terms of predictive accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, ElasticNet, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/rodolfomendes/abalone-dataset?dataset_version_number=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 57.3k/57.3k [00:00<00:00, 24.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"rodolfomendes/abalone-dataset\")\n",
    "csv_path = os.path.join(path, \"abalone.csv\") \n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the categorical variables\n",
    "df = pd.get_dummies(df, columns=['Sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the target variable\n",
    "X = df.drop(columns=['Rings'])  \n",
    "y = df['Rings']                 \n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa1bea9e94840009667d2dac3d9080e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.891232447128581\n",
      "R^2 Score: 0.5481628137889261\n"
     ]
    }
   ],
   "source": [
    "# Defining the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Track the experiment using MLflow\n",
    "with mlflow.start_run(run_name=\"Linear Regression Experiment\"):\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Log parameters and metrics to MLflow\n",
    "    mlflow.log_param(\"model\", \"Linear Regression\")\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "     # Create an input example\n",
    "    input_example = pd.DataFrame(X_test_scaled[:5], columns=X.columns)  # Using the first 5 rows as an example\n",
    "\n",
    "    # Infer model signature (schema)\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "    # Log the model with input example and signature\n",
    "    mlflow.sklearn.log_model(model, \"linear_regression_model\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e98222d821463084a62447c79448b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.437235685045327\n",
      "R^2 Score: 0.49772469428649535\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost Regressor Experiment\"):\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    mlflow.log_param(\"model\", \"XGBoost Regressor\")\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Create an input example\n",
    "    input_example = pd.DataFrame(X_test_scaled[:5], columns=X.columns)\n",
    "\n",
    "    # Infer model signature (schema)\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "    # Log the model with input example and signature\n",
    "    mlflow.sklearn.log_model(model, \"xgboost_regressor_model\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1298\n",
      "[LightGBM] [Info] Number of data points in the train set: 3341, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 9.944627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1baadb48fd45ad808b6211613a1a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.0601262594226855\n",
      "R^2 Score: 0.5325609167741505\n"
     ]
    }
   ],
   "source": [
    "# LGBM Regressor\n",
    "model = LGBMRegressor(random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name=\"LGBM Regressor Experiment\"):\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    mlflow.log_param(\"model\", \"LGBM Regressor\")\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Create an input example\n",
    "    input_example = pd.DataFrame(X_test_scaled[:5], columns=X.columns)\n",
    "\n",
    "    # Infer model signature (schema)\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "    # Log the model with input example and signature\n",
    "    mlflow.sklearn.log_model(model, \"lgbm_regressor_model\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c34073e5c14e35bcb0ff6bf89d5c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.107539234449761\n",
      "R^2 Score: 0.5281810502563149\n"
     ]
    }
   ],
   "source": [
    "# RandomForest Regressor\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest Regressor Experiment\"):\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    mlflow.log_param(\"model\", \"RandomForest Regressor\")\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Create an input example\n",
    "    input_example = pd.DataFrame(X_test_scaled[:5], columns=X.columns)\n",
    "\n",
    "    # Infer model signature (schema)\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "    # Log the model with input example and signature\n",
    "    mlflow.sklearn.log_model(model, \"randomforest_regressor_model\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6998a0af72fb4458baa0770f802a9e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.095921650201711\n",
      "R^2 Score: 0.5292542473766624\n"
     ]
    }
   ],
   "source": [
    "# GradientBoosting Regressor\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name=\"GradientBoosting Regressor Experiment\"):\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    mlflow.log_param(\"model\", \"GradientBoosting Regressor\")\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Create an input example\n",
    "    input_example = pd.DataFrame(X_test_scaled[:5], columns=X.columns)\n",
    "\n",
    "    # Infer model signature (schema)\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "    # Log the model with input example and signature\n",
    "    mlflow.sklearn.log_model(model, \"gradientboosting_regressor_model\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70039899009473581ec35c8730d0806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.995821172248803\n",
      "R^2 Score: 0.5385012252673118\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Regressor\n",
    "model = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Extra Trees Regressor Experiment\"):\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    mlflow.log_param(\"model\", \"Extra Trees Regressor\")\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Create an input example\n",
    "    input_example = pd.DataFrame(X_test_scaled[:5], columns=X.columns)\n",
    "\n",
    "    # Infer model signature (schema)\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "    # Log the model with input example and signature\n",
    "    mlflow.sklearn.log_model(model, \"extra_trees_regressor_model\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd428798638948898bd53b5d5a650f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.891051067434373\n",
      "R^2 Score: 0.5481795690937604\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regressor\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Ridge Regressor Experiment\"):\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    mlflow.log_param(\"model\", \"Ridge Regressor\")\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Create an input example\n",
    "    input_example = pd.DataFrame(X_test_scaled[:5], columns=X.columns)\n",
    "\n",
    "    # Infer model signature (schema)\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "    # Log the model with input example and signature\n",
    "    mlflow.sklearn.log_model(model, \"ridge_regressor_model\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcb874a1665411287f2bb7559bc1168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.0931497198849875\n",
      "R^2 Score: 0.34475638901844086\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regressor\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "\n",
    "with mlflow.start_run(run_name=\"ElasticNet Regressor Experiment\"):\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    mlflow.log_param(\"model\", \"ElasticNet Regressor\")\n",
    "    mlflow.log_param(\"scaling\", \"StandardScaler\")\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Create an input example\n",
    "    input_example = pd.DataFrame(X_test_scaled[:5], columns=X.columns)\n",
    "\n",
    "    # Infer model signature (schema)\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "    # Log the model with input example and signature\n",
    "    mlflow.sklearn.log_model(model, \"elasticnet_regressor_model\", signature=signature, input_example=input_example)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Extended Ridge: {'alpha': 1.0, 'fit_intercept': True, 'solver': 'lsqr'}\n",
      "Best MSE for Extended Ridge: 4.889262037394461\n",
      "Test MSE for Extended Ridge: 4.891051067370753\n",
      "Test R² for Extended Ridge: 0.5481795690996374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hocine/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "70 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hocine/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hocine/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hocine/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 1161, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hocine/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 838, in fit\n",
      "    raise ValueError(\n",
      "ValueError: 'lbfgs' solver can be used only when positive=True. Please use another solver.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/hocine/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [  -4.88949928   -4.88949928   -4.88949928   -4.88949928   -4.88957204\n",
      "           nan -104.30875698 -104.30875698 -104.30875698 -104.30661588\n",
      " -104.30865695           nan   -4.88949064   -4.88949064   -4.88949064\n",
      "   -4.88949064   -4.88956563           nan -104.30868434 -104.30868434\n",
      " -104.30868434 -104.30654559 -104.30857318           nan   -4.88941146\n",
      "   -4.88941146   -4.88941146   -4.88941146   -4.88948577           nan\n",
      " -104.30796792 -104.30796792 -104.30796792 -104.30585251 -104.30785012\n",
      "           nan   -4.88926204   -4.88926204   -4.88926204   -4.88926204\n",
      "   -4.88937651           nan -104.30170644 -104.30170644 -104.30170644\n",
      " -104.29923574 -104.30166064           nan   -4.91271093   -4.91271093\n",
      "   -4.91271093   -4.91271093   -4.91290405           nan -104.28153165\n",
      " -104.28153165 -104.28153165 -104.28613951 -104.28166653           nan\n",
      "   -5.11209521   -5.11209521   -5.11209521   -5.1121176    -5.11211228\n",
      "           nan -104.36526545 -104.36526545 -104.36526545 -104.36518912\n",
      " -104.36526686           nan   -6.03948785   -6.03948785   -6.03948785\n",
      "   -6.03947051   -6.03950491           nan -105.16444157 -105.16444157\n",
      " -105.16444157 -105.16423843 -105.16451105           nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    " # Extended parameter grid for Ridge Regression (without 'normalize')\n",
    "extended_ridge_param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],  # Wider range of alpha\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sag', 'lbfgs'],  # Different solvers for optimization\n",
    "    'fit_intercept': [True, False]  # Whether to calculate the intercept for this model\n",
    "}\n",
    "\n",
    "# Initialize the Ridge Regressor\n",
    "ridge_extended = Ridge()\n",
    "\n",
    "# Use GridSearchCV for tuning the hyperparameters\n",
    "ridge_extended_grid_search = GridSearchCV(estimator=ridge_extended, param_grid=extended_ridge_param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "ridge_extended_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and performance\n",
    "best_extended_ridge_model = ridge_extended_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Extended Ridge: {ridge_extended_grid_search.best_params_}\")\n",
    "print(f\"Best MSE for Extended Ridge: {-ridge_extended_grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_extended_ridge = best_extended_ridge_model.predict(X_test_scaled)\n",
    "mse_extended_ridge = mean_squared_error(y_test, y_pred_extended_ridge)\n",
    "r2_extended_ridge = r2_score(y_test, y_pred_extended_ridge)\n",
    "\n",
    "print(f\"Test MSE for Extended Ridge: {mse_extended_ridge}\")\n",
    "print(f\"Test R² for Extended Ridge: {r2_extended_ridge}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
